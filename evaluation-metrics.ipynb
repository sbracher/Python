{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "Classification Metrics:\n",
    "* Classification Accuracy\n",
    "* Logarithmic Loss\n",
    "* Area Under ROC Curve\n",
    "* Confusion Matrix\n",
    "* Classification Report\n",
    "\n",
    "Regression Metrics:\n",
    "* Mean Absolute Error\n",
    "* Mean Squared Error\n",
    "* R Squared ($R^2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import math\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics\n",
    "This example uses the Pima Indians diabetes dataset as this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these examples use the Pima Indian diabetes dataset\n",
    "url = \"pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate array into features (X) and label (y) parts\n",
    "X = array[:,0:8]\n",
    "y = array[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy\n",
    "The number of correct predictions vs all predictions made. This is the most common evaluation metric for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770 (0.048)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 8\n",
    "\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "\n",
    "scoring = 'accuracy'\n",
    "results = cross_validation.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic Loss\n",
    "Also known as logloss. Each prediction given as a value between 0 and 1 (probability of belonging to a particular class). This metric evaluates by rewarding or punishing in proportion to the confidence (assumed by the prabability) of the prediction. The smaller the logloss result, the better (zero is perfect logloss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: -0.493 (0.047)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 8\n",
    "\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_validation.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For metrics where the smallest score is best, the `cross_val_score` function reports these as negative values so that they can be sorted in ascending order so that the largest score is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under ROC Curve (AUC)\n",
    "Represents a model's ability to discriminate between positive and negative classes. An area of 1.0 represents a perfect model (all predictions are correct) whereas an area on 0.5 represents a worthless model (as good as a coin toss). Rough guide:\n",
    "* Area of 0.9 - 1.0 = excellent\n",
    "* Area of 0.8 - 0.9 = good\n",
    "* Area of 0.7 - 0.8 = fair\n",
    "* Area of 0.6 - 0.7 = poor\n",
    "* Area of 0.5 - 0.6 = fail\n",
    "\n",
    "A Receiver Operating Characteristic (ROC) curve plots the true positive rate (i.e. sensitivity or \"recall\") against the false positive rate at various threshold settings. See http://gim.unmc.edu/dxtests/roc3.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 8\n",
    "\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "results = cross_validation.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Returns the number of false negatives, false positives (Type I error), true negatives (Type II error) and true positives. See https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[134  13]\n",
      " [ 38  46]]\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "seed = 8\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "matrix = confusion_matrix(y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "The scikit-learn library provides a report to give a quick idea of the model's accuracy using a number of measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.91      0.84       147\n",
      "        1.0       0.78      0.55      0.64        84\n",
      "\n",
      "avg / total       0.78      0.78      0.77       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "seed = 8\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For predicting if the class is 1.0: the precision is 78% and recall is 55% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics\n",
    "This example uses the Boston Home Price dataset as this is a regression problem (all input variables are numeric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these examples use the Boston Home Price dataset\n",
    "url = \"housing.data\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n",
    "'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(url, delim_whitespace=True, names=names)\n",
    "array = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate array into features (X) and label (y) parts\n",
    "X = array[:,0:13]\n",
    "y = array[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "The average of the absolute differences between predictions and actual values. Gives an idea of the magnitude of the error but not direction (i.e. over or under predicting). A value of zero indicates no error (i.e. perfect predictions). The lower the score, the better. Metric is negated by the `cross_val_score()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -4.005 (2.084)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 8\n",
    "\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = cross_validation.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"MAE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)\n",
    "Mean Squared Error is the average of the squared differences between predictions and actual values. Taking the square root converts the units back to the original units of the output variable (i.e. the Root Mean Squared Error). As with MAE, the lower the score, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 34.705 (45.574)\n",
      "MSE: 5.891 (6.751)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 8\n",
    "\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LinearRegression()\n",
    "\n",
    "# MSE\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_validation.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"MSE: %.3f (%.3f)\" % (abs(results.mean()), abs(results.std())))\n",
    "\n",
    "# RMSE\n",
    "print(\"MSE: %.3f (%.3f)\" % (math.sqrt(abs(results.mean())), math.sqrt(abs(results.std()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Squared ($R^2$)\n",
    "Gives an indication of the goodness of fit (\"coefficient of determination\") of a set of predictions to the actual values. It's a statistical measure of how close the data are to the fitted regression line. The result is a value between 0 (indicating no fit) and 1 (indicating perfect fit). More info: http://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.203 (0.595)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "seed = 8\n",
    "\n",
    "kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = 'r2'\n",
    "results = cross_validation.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "print(\"R^2: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
